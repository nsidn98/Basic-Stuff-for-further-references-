{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/siddharthnayak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    data['tags'] = data['tags'].apply(literal_eval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=read_data('/Users/siddharthnayak/Downloads/natural-language-processing-master/data/train.tsv')\n",
    "validation=read_data('/Users/siddharthnayak/Downloads/natural-language-processing-master/data/validation.tsv')\n",
    "test=pd.read_csv('/Users/siddharthnayak/Downloads/natural-language-processing-master/data/test.tsv',sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>[php, mysql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                  tags\n",
       "0                How to draw a stacked dotplot in R?                   [r]\n",
       "1  mysql select all records where a datetime fiel...          [php, mysql]\n",
       "2             How to terminate windows phone 8.1 app                  [c#]\n",
       "3  get current time in a specific country via jquery  [javascript, jquery]\n",
       "4                      Configuring Tomcat to Use SSL                [java]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How to draw a stacked dotplot in R?',\n",
       "       'mysql select all records where a datetime field is less than a specified value',\n",
       "       'How to terminate windows phone 8.1 app', ...,\n",
       "       'Python Pandas Series of Datetimes to Seconds Since the Epoch',\n",
       "       'jqGrid issue grouping - Duplicate rows get appended every time sort is changed',\n",
       "       'Create a List of primitive int?'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['title'].values, train['tags'].values\n",
    "X_val, y_val = validation['title'].values, validation['tags'].values\n",
    "X_test = test['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower()# lowercase text\n",
    "    text =  REPLACE_BY_SPACE_RE.sub('',text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('',text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    sent = ''\n",
    "    for word in text.split():\n",
    "        if word not in STOPWORDS:\n",
    "            if sent=='':\n",
    "                sent=word\n",
    "            else:    \n",
    "                sent=sent+' '+word  # delete stopwords from text\n",
    "    text=sent        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_prepare():\n",
    "    examples = [\"SQL Server - any equivalent of Excel's CHOOSE function?\",\n",
    "                \"How to free c++ memory vector<int> * arr?\"]\n",
    "    answers = [\"sql server equivalent excels choose function\", \n",
    "               \"free c++ memory vectorint arr\"]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if text_prepare(ex) != ans:\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [text_prepare(x) for x in X_train]\n",
    "X_val = [text_prepare(x) for x in X_val]\n",
    "X_test = [text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all tags from train corpus with their counts.\n",
    "tags_counts = {}\n",
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = {}\n",
    "for words in X_train:\n",
    "    for word in words.split():\n",
    "        if word in words_counts:\n",
    "            words_counts[word]+=1\n",
    "        else:\n",
    "            words_counts[word]=1\n",
    "            \n",
    "for words in train['tags']:\n",
    "    for word in words:\n",
    "        if word in tags_counts:\n",
    "            tags_counts[word]+=1\n",
    "        else:\n",
    "            tags_counts[word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('javascript', 19078), ('c#', 19077), ('java', 18661)] [('using', 8274), ('php', 5422), ('java', 5397)]\n"
     ]
    }
   ],
   "source": [
    "most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "print(most_common_tags,most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]\n",
    "#WORDS_TO_INDEX \n",
    "WORDS_TO_INDEX ={}\n",
    "for i in range(DICT_SIZE):\n",
    "    WORDS_TO_INDEX [most_common_words[i][0]]=i\n",
    "       \n",
    "    \n",
    "#INDEX_TO_WORDS = ####### YOUR CODE HERE #######\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    text=text.split() # get the words in the sentence\n",
    "    for word in text:\n",
    "        i=words_to_index.get(word)\n",
    "        if i!=None:\n",
    "            result_vector[i]=1\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (100000, 5000)\n",
      "X_val shape  (30000, 5000)\n",
      "X_test shape  (20000, 5000)\n"
     ]
    }
   ],
   "source": [
    "#Compressed sparse matrix\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "row = X_train_mybag[10].toarray()[0]\n",
    "non_zero_elements_count =np.count_nonzero(row)\n",
    "print(non_zero_elements_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task WordsTagsCount is:\n",
      " javascript,c#,java\n",
      "using,php,java,file,javascript,error,get,c#,python,string,array,data,value,jquery...\n",
      "Current answer for task BagOfWords is:\n",
      " 7...\n"
     ]
    }
   ],
   "source": [
    "from grader import Grader\n",
    "grader = Grader()\n",
    "grader.submit_tag('WordsTagsCount', '%s\\n%s' % (','.join(tag for tag, _ in most_common_tags), \n",
    "                                                ','.join(word for word, _ in most_common_words)))\n",
    "grader.submit_tag('BagOfWords', str(non_zero_elements_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test, and val sets and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=5,max_df=0.9,ngram_range=(1,2),token_pattern='(\\S+)')\n",
    "    features=tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_train=pd.DataFrame(features.todense(),columns=tfidf_vectorizer.get_feature_names())\n",
    "   \n",
    "    X_val=tfidf_vectorizer.transform(X_val)\n",
    "    X_val=X_val.todense()\n",
    "    #X_val=pd.DataFrame(features.todense(),columns=tfidf_vectorizer.get_feature_names())\n",
    "    \n",
    "    \n",
    "    X_test=tfidf_vectorizer.transform(X_test)\n",
    "    X_test=X_test.todense()\n",
    "    #X_test=pd.DataFrame(features.todense(),columns=tfidf_vectorizer.get_feature_names())\n",
    "    \n",
    "\n",
    "    \n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 17966), (30000, 17966), (20000, 17966))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape,X_val_tfidf.shape,X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1839\n"
     ]
    }
   ],
   "source": [
    "for name, age in tfidf_reversed_vocab.items():    # for name, age in list.items():  (for Python 3.x)\n",
    "    if age == 'c#':\n",
    "        print (name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import multiclass\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_val = mlb.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training data\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    logreg = linear_model.LogisticRegression(verbose=True)\n",
    "    clf = multiclass.OneVsRestClassifier(logreg)\n",
    "    fit=clf.fit(X_train,y_train)\n",
    "    # Create and fit LogisticRegression wraped into OneVsRestClassifier.\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "classifier_mybag = train_classifier(X_train_mybag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 17966)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\todbc_exec always fail\n",
      "True labels:\tphp,sql\n",
      "Predicted labels:\t\n",
      "\n",
      "\n",
      "Title:\taccess base classes variable within child class\n",
      "True labels:\tjavascript\n",
      "Predicted labels:\t\n",
      "\n",
      "\n",
      "Title:\tcontenttype applicationjson required rails\n",
      "True labels:\truby,ruby-on-rails\n",
      "Predicted labels:\truby-on-rails\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_tfidf)\n",
    "y_val_inversed = mlb.inverse_transform(y_val)\n",
    "for i in range(3):\n",
    "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        X_val[i],\n",
    "        ','.join(y_val_inversed[i]),\n",
    "        ','.join(y_val_pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    print(accuracy_score(y_val, predicted))\n",
    "    print(f1_score(y_val, predicted, average=None))\n",
    "    print(roc_auc_score(y_val, predicted))\n",
    "    print(average_precision_score(y_val, predicted))\n",
    "    print(recall_score(y_val, predicted,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words\n",
      "0.3563\n",
      "[ 0.13936249  0.60021668  0.22988506  0.69887955  0.86522911  0.32820513\n",
      "  0.48741007  0.53652835  0.44680851  0.62450593  0.76664345  0.68297272\n",
      "  0.06451613  0.02484472  0.87272727  0.39634941  0.68548387  0.056\n",
      "  0.23148148  0.34285714  0.83387622  0.20111732  0.69411765  0.66242038\n",
      "  0.6618705   0.8516129   0.05853659  0.19941349  0.05031447  0.66055046\n",
      "  0.71653543  0.72636816  0.32997602  0.37536657  0.15909091  0.52051282\n",
      "  0.38863636  0.80754561  0.8326766   0.62407862  0.74161378  0.61488673\n",
      "  0.81553398  0.688       0.37536657  0.3255814   0.0661157   0.54455446\n",
      "  0.72316384  0.48251748  0.63989108  0.68478261  0.66666667  0.73516386\n",
      "  0.09160305  0.80203046  0.44933921  0.82987552  0.13333333  0.17391304\n",
      "  0.82785352  0.42424242  0.82025528  0.05369128  0.10752688  0.68669528\n",
      "  0.79207921  0.71759891  0.48421053  0.53139217  0.76428175  0.09090909\n",
      "  0.70689655  0.52972973  0.4950495   0.59701493  0.4640884   0.65\n",
      "  0.53594771  0.25420561  0.32340426  0.26470588  0.75833333  0.69026549\n",
      "  0.70411985  0.62008734  0.472103    0.26785714  0.57244656  0.2231405\n",
      "  0.26126126  0.8         0.49295775  0.16969697  0.37699681  0.78676471\n",
      "  0.67724868  0.25766871  0.28571429  0.62023217]\n",
      "0.702483269201\n",
      "0.342247378148\n",
      "[ 0.08209607  0.48342059  0.1369863   0.55567929  0.78484108  0.22222222\n",
      "  0.4234375   0.39913043  0.33070866  0.48565574  0.67225131  0.55504587\n",
      "  0.03680982  0.01351351  0.79620853  0.27992634  0.64885496  0.03255814\n",
      "  0.17006803  0.25149701  0.72180451  0.12587413  0.55660377  0.55026455\n",
      "  0.59354839  0.825       0.03296703  0.13438735  0.02721088  0.5625\n",
      "  0.66423358  0.58634538  0.23433243  0.25396825  0.09859155  0.41985522\n",
      "  0.28264463  0.71024479  0.76794895  0.50285966  0.66074313  0.4679803\n",
      "  0.77777778  0.59930314  0.2601626   0.22340426  0.04040404  0.39568345\n",
      "  0.58715596  0.37398374  0.51591658  0.53617021  0.50967742  0.63407181\n",
      "  0.05172414  0.67521368  0.30722892  0.72992701  0.08547009  0.10526316\n",
      "  0.73128689  0.33070866  0.7195301   0.02898551  0.05952381  0.54421769\n",
      "  0.6779661   0.61448598  0.36220472  0.40725244  0.65556613  0.05726872\n",
      "  0.64566929  0.40163934  0.41666667  0.48484848  0.37168142  0.54166667\n",
      "  0.41414141  0.1748072   0.22222222  0.18828452  0.62186788  0.55450237\n",
      "  0.58024691  0.4965035   0.36666667  0.2027027   0.41056218  0.14835165\n",
      "  0.16201117  0.7008547   0.40462428  0.10606061  0.25877193  0.65644172\n",
      "  0.53481894  0.16535433  0.18518519  0.53276353]\n",
      "Tfidf\n",
      "0.329933333333\n",
      "[ 0.12097408  0.56849315  0.125       0.66569343  0.83707865  0.2\n",
      "  0.4114053   0.48511166  0.37426901  0.58635097  0.751962    0.64637777\n",
      "  0.05747126  0.          0.83646113  0.33001422  0.58064516  0.075\n",
      "  0.18947368  0.3196347   0.8215859   0.06493506  0.65030675  0.57839721\n",
      "  0.53333333  0.79442509  0.0212766   0.16828479  0.01290323  0.57286432\n",
      "  0.70247934  0.67191601  0.2927078   0.33639144  0.128       0.45844875\n",
      "  0.33204633  0.78468285  0.81862841  0.60672221  0.70678128  0.5467128\n",
      "  0.72592593  0.62857143  0.31309904  0.26720648  0.03539823  0.38202247\n",
      "  0.53333333  0.40545809  0.62597587  0.55757576  0.59728507  0.64760058\n",
      "  0.01709402  0.7173913   0.43119266  0.77678571  0.07751938  0.08465608\n",
      "  0.80976686  0.29585799  0.77913575  0.01342282  0.05882353  0.55660377\n",
      "  0.75328084  0.70588235  0.37349398  0.50530376  0.72526193  0.06299213\n",
      "  0.6728972   0.34782609  0.29585799  0.50833333  0.40251572  0.62576687\n",
      "  0.4893617   0.15800416  0.30769231  0.19736842  0.74571429  0.51546392\n",
      "  0.62348178  0.51231527  0.38423645  0.26804124  0.55036855  0.15454545\n",
      "  0.22115385  0.69189189  0.46969697  0.14603175  0.28521127  0.70355731\n",
      "  0.66300366  0.15068493  0.24477612  0.59139785]\n",
      "0.666944328331\n",
      "0.297495924891\n",
      "[ 0.06724891  0.43455497  0.06849315  0.5077951   0.72860636  0.11805556\n",
      "  0.315625    0.34        0.2519685   0.43135246  0.63542757  0.49796126\n",
      "  0.03067485  0.          0.73933649  0.21362799  0.48091603  0.04186047\n",
      "  0.12244898  0.20958084  0.70112782  0.03496503  0.5         0.43915344\n",
      "  0.41290323  0.7125      0.01098901  0.1027668   0.00680272  0.4453125\n",
      "  0.62043796  0.51405622  0.19550409  0.21825397  0.07511737  0.34229576\n",
      "  0.21322314  0.66509519  0.73852154  0.46458425  0.59773829  0.38916256\n",
      "  0.60493827  0.49825784  0.19918699  0.17553191  0.02020202  0.24460432\n",
      "  0.36697248  0.28184282  0.48408342  0.39148936  0.42580645  0.51031322\n",
      "  0.00862069  0.56410256  0.28313253  0.6350365   0.04273504  0.04678363\n",
      "  0.69303424  0.19685039  0.65528634  0.00724638  0.03571429  0.40136054\n",
      "  0.60805085  0.57476636  0.24409449  0.36541144  0.59276879  0.03524229\n",
      "  0.56692913  0.2295082   0.20833333  0.36969697  0.28318584  0.5\n",
      "  0.34848485  0.09768638  0.19883041  0.12552301  0.59453303  0.35545024\n",
      "  0.47530864  0.36363636  0.26        0.17567568  0.38160136  0.09340659\n",
      "  0.12849162  0.54700855  0.3583815   0.08712121  0.17763158  0.54601227\n",
      "  0.50417827  0.08661417  0.15185185  0.47008547]\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print('Tfidf')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c1e4a103b15e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_predicted_scores_mybag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "n_classes = len(tags_counts)\n",
    "roc_curve(y_val, y_val_predicted_scores_mybag, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

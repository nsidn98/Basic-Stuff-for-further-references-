{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthnayak/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import time,pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEX4gaAIPxAU4QeCIvxAUIQfCOq/esVX4lsZQ0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128e2d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(mnist.train.images[0],(28,28)),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Generator Function\n",
    " The function `generator(z)` takes 256-dimensional vector and returns 784-dimensional vector, which is MNIST image (28x28). z here is the prior for the $G(Z)$. In a way it learns a mapping between the prior space to $P_{data}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G(z)\n",
    "def generator(x):\n",
    "    '''\n",
    "    The generator network with a vanilla Neural Net with 2 hidden layers\n",
    "    '''\n",
    "    w_init = tf.truncated_normal_initializer(mean=0,stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.)\n",
    "    \n",
    "    #layer 1\n",
    "    w_0 = tf.get_variable('Gen_w0',[x.get_shape()[1],256],initializer=w_init)\n",
    "    b_0 = tf.get_variable('Gen_b0',[256],initializer=b_init)\n",
    "    h_0 = tf.nn.relu(tf.matmul(x,w_0)+b_0)\n",
    "    \n",
    "    #layer 2\n",
    "    w_1 = tf.get_variable('Gen_w1',[h_0.get_shape()[1],512],initializer=w_init)\n",
    "    b_1 = tf.get_variable('Gen_b1',[512],initializer=b_init)\n",
    "    h_1 = tf.nn.relu(tf.matmul(h_0,w_1)+b_1)\n",
    "    \n",
    "    #layer 3\n",
    "    w_2 = tf.get_variable('Gen_w2',[h_1.get_shape()[1],1024],initializer=w_init)\n",
    "    b_2 = tf.get_variable('Gen_b2',[1024],initializer=b_init)\n",
    "    h_2 = tf.nn.relu(tf.matmul(h_1,w_2)+b_2)\n",
    "    \n",
    "    #output\n",
    "    w_3 = tf.get_variable('Gen_w3',[h_2.get_shape()[1],784],initializer=w_init)\n",
    "    b_3 = tf.get_variable('Gen_b3',[784],initializer=b_init)\n",
    "    out = tf.nn.tanh(tf.matmul(h_2,w_3)+b_3)\n",
    "    \n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Discriminator Function\n",
    "This takes in an image and gives out the probability of a real MNIST image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D(z)\n",
    "def discriminator(x,drop_out):\n",
    "    '''\n",
    "    The discriminator network with a vanilla Neural Net with 3 hidden layers\n",
    "    This beast produces the output prediction which may be given as a feed back \n",
    "    to the Generator network to train.\n",
    "    '''\n",
    "    w_init = tf.truncated_normal_initializer(mean=0,stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.)\n",
    "    \n",
    "    #layer 1\n",
    "    w_0 = tf.get_variable('Dis_w0',[x.get_shape()[1],1024],initializer=w_init)\n",
    "    b_0 = tf.get_variable('Dis_b0',[1024],initializer=b_init)\n",
    "    h_0 = tf.nn.relu(tf.matmul(x,w_0)+b_0)\n",
    "    h_0 = tf.nn.dropout(h_0, drop_out)\n",
    "    \n",
    "    #layer 2\n",
    "    w_1 = tf.get_variable('Dis_w1',[h_0.get_shape()[1],512],initializer=w_init)\n",
    "    b_1 = tf.get_variable('Dis_b1',[512],initializer=b_init)\n",
    "    h_1 = tf.nn.relu(tf.matmul(h_0,w_1)+b_1)\n",
    "    h_1 = tf.nn.dropout(h_1, drop_out)\n",
    "    \n",
    "    #layer 3\n",
    "    w_2 = tf.get_variable('Dis_w2',[h_1.get_shape()[1],256],initializer=w_init)\n",
    "    b_2 = tf.get_variable('Dis_b2',[256],initializer=b_init)\n",
    "    h_2 = tf.nn.relu(tf.matmul(h_1,w_2)+b_2)\n",
    "    h_2 = tf.nn.dropout(h_2, drop_out)\n",
    "    \n",
    "    #output\n",
    "    w_3 = tf.get_variable('Dis_w3',[h_2.get_shape()[1],1],initializer=w_init)\n",
    "    b_3 = tf.get_variable('Dis_b3',[1],initializer=b_init)\n",
    "    out = tf.nn.sigmoid(tf.matmul(h_2,w_3)+b_3) #sigmoid because we want probability and \n",
    "    #sigmoid can be interpretated as a probability\n",
    "    \n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(num_epoch,show=False,save=False,path='/Users/siddharthnayak/Downloads/GAN/result.png'):\n",
    "    z_ = np.random.normal(0, 1, (25, 100))\n",
    "    test_img = sess.run(G_z,{z:z_,drop_out:0.0})\n",
    "    size_figure_grid = 5\n",
    "    \n",
    "    size_figure_grid = 5\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i, j].get_xaxis().set_visible(False)\n",
    "        ax[i, j].get_yaxis().set_visible(False)\n",
    "\n",
    "    for k in range(5*5):\n",
    "        i = k // 5\n",
    "        j = k % 5\n",
    "        ax[i, j].cla()\n",
    "        ax[i, j].imshow(np.reshape(test_img[k], (28, 28)), cmap='gray')\n",
    "\n",
    "    label = 'Epoch {0}'.format(num_epoch)\n",
    "    fig.text(0.5, 0.04, label, ha='center')\n",
    "    plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_hist(hist, show = False, save = False, path = '/Users/siddharthnayak/Downloads/GAN/train_hist.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['Dis_losses']\n",
    "    y2 = hist['Gen_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='Dis_loss')\n",
    "    plt.plot(x, y2, label='Gen_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 100\n",
    "lr = 0.0002\n",
    "train_epoch = 100\n",
    "eps=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(t_set):\n",
    "    return (t_set-0.5)/0.5\n",
    "\n",
    "train_set = normalize(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting on tensorboard \n",
    "with tf.variable_scope('Generator_net') as scope1:\n",
    "    z = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "    G_z = generator(z) #call the generator function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Discriminator_net') as scope:\n",
    "    drop_out = tf.placeholder(dtype = tf.float32,name='Drop_out')\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "    D_real = discriminator(x,drop_out)\n",
    "    scope.reuse_variables() #because i am lazy to write it again\n",
    "    D_fake = discriminator(G_z,drop_out)\n",
    "#here D_fake means D(G(z)) and D_real means D(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main equation in GAN :p\n",
    "$\\underset{G}{min}\\underset{D}{max}V(D,G) = \\mathbb{E}_{x\\sim{p_{data}(x)}} [log D(x)]+\\mathbb{E}_{z\\sim{p_z(z)}} [log(1-D(G(x)))]$<br/>\n",
    "The algorithm for the updates can be found in the paper by Ian Goodfellow,et al. NIPS 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss \n",
    "Dis_loss = tf.reduce_mean(-tf.log(D_real+eps)-tf.log(1-D_fake+eps))\n",
    "Gen_loss = tf.reduce_mean(-tf.log(D_fake+eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainable variables for each network\n",
    "t_vars = tf.trainable_variables()\n",
    "Dis_vars = [var for var in t_vars if 'Dis_' in var.name]\n",
    "Gen_vars = [var for var in t_vars if 'Gen_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer for each network\n",
    "Dis_optim = tf.train.AdamOptimizer(lr).minimize(Dis_loss, var_list=Dis_vars)\n",
    "Gen_optim = tf.train.AdamOptimizer(lr).minimize(Gen_loss, var_list=Gen_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results save folder\n",
    "if not os.path.isdir('/Users/siddharthnayak/Downloads/GAN'):\n",
    "    os.mkdir('/Users/siddharthnayak/Downloads/GAN')\n",
    "if not os.path.isdir('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results'):\n",
    "    os.mkdir('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results')\n",
    "if not os.path.isdir('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/Random_results'):\n",
    "    os.mkdir('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/Random_results')\n",
    "if not os.path.isdir('/Users/siddharthnayak/Downloads/GAn/MNIST_GAN_results/Fixed_results'):\n",
    "    os.mkdir('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/Fixed_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open session and initialize all variables\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iitialize a dict for training history\n",
    "train_hist = {}\n",
    "train_hist['Dis_losses'] = []\n",
    "train_hist['Gen_losses'] = []\n",
    "train_hist['per_epoch_ptimes'] = []\n",
    "train_hist['total_ptime'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-452d64fbdb29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mz_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss_dis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDis_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDis_optim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_out\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#evaluate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mDis_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training time (finally)\n",
    "np.random.seed(int(time.time()))\n",
    "start_time = time.time()\n",
    "for epoch in range(train_epoch):\n",
    "    print('Starting epoch %d'%epoch)\n",
    "    Gen_losses = []\n",
    "    Dis_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for iter in range(train_set.shape[0] // batch_size):\n",
    "        if iter%100==0:\n",
    "            print(iter)\n",
    "        # update discriminator\n",
    "        x_ = train_set[iter*batch_size:(iter+1)*batch_size]#get next batch\n",
    "        z_ = np.random.normal(0, 1, (batch_size, 100))\n",
    "        \n",
    "        loss_dis,_ = sess.run([Dis_loss, Dis_optim],{x: x_, z: z_, drop_out: 0.3})#evaluate the loss\n",
    "        Dis_losses.append(loss_dis)\n",
    "        \n",
    "        loss_gen,_=sess.run([Gen_loss, Gen_optim],{z:z_,drop_out:0.3})#evaluate the loss\n",
    "        Gen_losses.append(loss_gen)\n",
    "        \n",
    "        \n",
    "    #print info about each epoch\n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "    print('[%d/%d] - ptime: %.2f loss_dis: %.3f, loss_gen: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime, np.mean(Dis_losses), np.mean(Gen_losses)))\n",
    "    p = '/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/Random_results/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "    fixed_p = '/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/Fixed_results/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "    show((epoch + 1), save=True, path=p)\n",
    "    show((epoch + 1), save=True, path=fixed_p)\n",
    "    train_hist['Dis_losses'].append(np.mean(Dis_losses))\n",
    "    train_hist['Gen_losses'].append(np.mean(Gen_losses))\n",
    "    train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "    \n",
    "end_time = time.time()\n",
    "total_ptime = end_time - start_time\n",
    "train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(train_hist['per_epoch_ptimes']), train_epoch, total_ptime))\n",
    "print(\"Training finish!... save training results\")\n",
    "with open('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/train_hist.pkl', 'wb') as f:\n",
    "    pickle.dump(train_hist, f)\n",
    "show_train_hist(train_hist, save=True, path='MNIST_GAN_results/MNIST_GAN_train_hist.png')\n",
    "\n",
    "images = []\n",
    "for e in range(train_epoch):\n",
    "    img_name = '/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/Fixed_results/MNIST_GAN_' + str(e + 1) + '.png'\n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave('/Users/siddharthnayak/Downloads/GAN/MNIST_GAN_results/generation_animation.gif', images, fps=5)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
